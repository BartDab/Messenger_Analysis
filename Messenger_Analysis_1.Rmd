---
title: "Messenger_1"
author: "Bartosz Dąbrowski"
date: "4 05 2020"
output: html_document
---

```{r}
library(jsonlite)
library(lubridate)
library(tidyverse)
library(tidytext)
library(stringi)
library(tm)
library(readxl)
library(qdapRegex)
library(viridisLite)
```


```{r}
data1<-jsonlite::fromJSON(txt='E:/messages/inbox/KubaNatonek_KcMgnu4_HA/data1.txt')
data2<-jsonlite::fromJSON(txt='E:/messages/inbox/KubaNatonek_KcMgnu4_HA/data2.txt')
data3<-jsonlite::fromJSON(txt='E:/messages/inbox/KubaNatonek_KcMgnu4_HA/data3.txt')
data4<-jsonlite::fromJSON(txt='E:/messages/inbox/KubaNatonek_KcMgnu4_HA/data4.txt')
```



```{r}

data_msg_comb<-rbind(data1$messages[1:3],data2$messages[1:3],data3$messages[1:3],data4$messages[1:3])

options(digits.secs=6)
data_msg_comb[,2]<-as.POSIXct(as.vector(data_msg_comb[,2])/1000,origin=lubridate::origin)

str(data_msg_comb)
```

```{r}
df1<-tidyr::separate(data_msg_comb,col=timestamp_ms,
           into=c('Date','Time'),
           sep=" ")
```


```{r}
df1<-df1%>%
  group_by(sender_name,Date)%>%
  count(content)
ggplot(df1, aes(x=Date,y=n))+geom_col()


```


```{r}
data_text<-data_msg_comb%>%
  tibble::rowid_to_column("doc_id")
data_text<-data_text[,c('doc_id','content','sender_name','timestamp_ms')]
colnames(data_text)<-c('doc_id','text','sender_name','timestamp_ms')
data_short<-data_text[1:15000,]
```



```{r}
#emoji<-read_xlsx('E:/asd/emoticon_conversion.xlsx')
#colnames(emoji)<-c('a','b','c','d','e','f','g','Unicode','Bytes','Description')
#data_no_emoji$text<-removeWords(data_no_emoji$text,emoji$Bytes)
```



```{r}
data_no_emoji<-data_short
data_no_emoji$text<-rm_url(data_no_emoji$text)
data_no_emoji$text<-gsub("[^A-Za-zĄąćĆĘęŁłŃńóÓŚśŻżŹź0-9]"," ",data_no_emoji$text)
unwanted_array = list('Ą'="A",'ą'='a','ć'='c','Ć'='C','Ę'='E','ę'='e','Ł'='L','ł'='l','Ń'="N",'ń'='n','ó'='o','Ó'='O','Ś'='S','ś'='s','Ż'='Z','ż'='z','ź'='z','Ź'='Z')
data_no_emoji$text<-chartr(paste(names(unwanted_array), collapse=''),
         paste(unwanted_array, collapse=''),
         data_no_emoji$text)
nanotek<-dplyr::filter(data_no_emoji, grepl('nanotek', text))

nanotek<-dplyr::filter(data_no_emoji, grepl('bartosz', text))
custom_stop<-c('nanotek','you','your','call','chat','theme','the','called','missed','sent','nickname','has','turned','played','tez','wiec','bym','now','mial','mialem','bym','miec','maja','masz','turn','attachment','kuba','bartosz')
```

```{r}
data_source<-DataframeSource(data_no_emoji)
data_corpus<-VCorpus(data_source)
data_corpus
```

```{r}
stopwords <- read_csv("E:/asd/polish.stopwords.txt", 
    col_names = FALSE)
head(stopwords)
```

```{r}
data_clean<-tm_map(data_corpus,removePunctuation)
data_clean<-tm_map(data_clean, content_transformer(tolower))
data_clean<-tm_map(data_clean,stripWhitespace)
data_clean<-tm_map(data_clean,removeWords,stopwords$X1)
data_clean<-tm_map(data_clean,removeWords,custom_stop)
```
#there's a problem with emoji
NO MORE :)
```{r}
data_tdm<-TermDocumentMatrix(data_clean)
data_tdm
```

```{r}
gc()
data_m<-as.matrix(data_tdm)
dim(data_m)
```

```{r}
freq <- rowSums(data_m)
freq <- sort(freq,decreasing=TRUE)
```


```{r}
str(freq)
head(freq,64)
barplot(freq[1:10], col = "tan", las = 2)
```


```{r}
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "Me vs Natonek")
wordcloud(names(freq),freq,max.words=50,color=cividis(1),main='Title')
```
